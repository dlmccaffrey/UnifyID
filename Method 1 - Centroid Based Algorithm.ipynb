{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centroid Anomaly Detection\n",
    "The following algorithm is based on Kloft M, Laskov P. <a href=\"http://proceedings.mlr.press/v9/kloft10a.html\">Online Anomaly Detection under Adversarial Impact</a>. Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics. 2010. pp. 405–412.\n",
    "\n",
    "The centroid algorithm computes the mean of the set of \"normal\" examples. New points are judged as inliers or outliers based on their Euclidean distance from the mean. The appealing part of this algorithm is its simplicity, both in implementing the original training (finding the mean) and in updating the model. Updating can be done in two ways: one where the number of total data points keeps increasing, or one where the number of data points is held constant and previous data points are removed. The second way is called a finite sliding training window.\n",
    "\n",
    "Kloft and Laskov found that using a finite sliding training window was resistant to poisoning attacks, so long as the attacker has limited access to the training data, which seems to be a reasonable assumption for real world attacks. This seems like an important consideration for learning algorithms, considering how <a href=\"http://www.evolvingai.org/fooling\">image classification algorithms can be fooled</a>.\n",
    "\n",
    "For the initial training, the only hyperparameter to tune is the threshold distance from the mean, $r$.\n",
    "$$ class = \n",
    "\\begin{cases}\n",
    "    \\text{inlier,} & d < r \\\\\n",
    "    \\text{outlier,} & d \\geq r\n",
    "\\end{cases} $$\n",
    "where $d$ is the Euclidean distance between the new point and the mean (centroid).\n",
    "\n",
    "See ```Data Exploration and Setup.ipynb``` for more information on the data set used and how it was split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load training data\n",
    "X_train = pd.read_csv('X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142403, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #should be (142403, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I can't determine unique credit cards, I'm going to drop the 'Time' feature. I'm also going to mean normalize the data. This should make calculations a bit simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.309615</td>\n",
       "      <td>0.118858</td>\n",
       "      <td>2.890224</td>\n",
       "      <td>3.259563</td>\n",
       "      <td>-0.975216</td>\n",
       "      <td>2.053227</td>\n",
       "      <td>-1.225558</td>\n",
       "      <td>1.224267</td>\n",
       "      <td>-0.036384</td>\n",
       "      <td>0.050075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301116</td>\n",
       "      <td>0.240538</td>\n",
       "      <td>0.707201</td>\n",
       "      <td>-0.251083</td>\n",
       "      <td>-0.450744</td>\n",
       "      <td>0.272565</td>\n",
       "      <td>0.567029</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>-0.040843</td>\n",
       "      <td>82.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.507604</td>\n",
       "      <td>-0.445468</td>\n",
       "      <td>0.383992</td>\n",
       "      <td>1.756901</td>\n",
       "      <td>-1.186740</td>\n",
       "      <td>0.489871</td>\n",
       "      <td>1.460411</td>\n",
       "      <td>0.438009</td>\n",
       "      <td>-0.487785</td>\n",
       "      <td>-0.816031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816683</td>\n",
       "      <td>0.340005</td>\n",
       "      <td>0.171648</td>\n",
       "      <td>0.960273</td>\n",
       "      <td>0.016460</td>\n",
       "      <td>-0.199284</td>\n",
       "      <td>-0.286972</td>\n",
       "      <td>-0.063034</td>\n",
       "      <td>0.074770</td>\n",
       "      <td>435.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.579097</td>\n",
       "      <td>-3.780828</td>\n",
       "      <td>0.915284</td>\n",
       "      <td>0.811619</td>\n",
       "      <td>1.384262</td>\n",
       "      <td>-1.373492</td>\n",
       "      <td>-1.609020</td>\n",
       "      <td>0.818499</td>\n",
       "      <td>-1.445239</td>\n",
       "      <td>0.202760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866831</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>-1.077871</td>\n",
       "      <td>0.391329</td>\n",
       "      <td>-0.448916</td>\n",
       "      <td>-0.352105</td>\n",
       "      <td>-0.870777</td>\n",
       "      <td>0.077323</td>\n",
       "      <td>-0.479606</td>\n",
       "      <td>189.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.198195</td>\n",
       "      <td>-0.493945</td>\n",
       "      <td>1.132765</td>\n",
       "      <td>-0.409765</td>\n",
       "      <td>-0.872015</td>\n",
       "      <td>0.871469</td>\n",
       "      <td>0.279736</td>\n",
       "      <td>0.418671</td>\n",
       "      <td>0.962524</td>\n",
       "      <td>-0.824186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186004</td>\n",
       "      <td>-0.001488</td>\n",
       "      <td>-0.152296</td>\n",
       "      <td>0.564498</td>\n",
       "      <td>0.738859</td>\n",
       "      <td>-0.708118</td>\n",
       "      <td>0.285887</td>\n",
       "      <td>-0.040291</td>\n",
       "      <td>0.018017</td>\n",
       "      <td>187.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.702706</td>\n",
       "      <td>1.432597</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.906160</td>\n",
       "      <td>-0.158996</td>\n",
       "      <td>-0.563226</td>\n",
       "      <td>0.375988</td>\n",
       "      <td>0.414078</td>\n",
       "      <td>-0.757303</td>\n",
       "      <td>-0.289653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018858</td>\n",
       "      <td>0.198920</td>\n",
       "      <td>0.667377</td>\n",
       "      <td>-0.051745</td>\n",
       "      <td>0.418866</td>\n",
       "      <td>-0.283271</td>\n",
       "      <td>-0.305879</td>\n",
       "      <td>0.312144</td>\n",
       "      <td>0.162622</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.309615  0.118858  2.890224  3.259563 -0.975216  2.053227 -1.225558   \n",
       "1 -1.507604 -0.445468  0.383992  1.756901 -1.186740  0.489871  1.460411   \n",
       "2 -3.579097 -3.780828  0.915284  0.811619  1.384262 -1.373492 -1.609020   \n",
       "3 -0.198195 -0.493945  1.132765 -0.409765 -0.872015  0.871469  0.279736   \n",
       "4 -0.702706  1.432597  0.997674  0.906160 -0.158996 -0.563226  0.375988   \n",
       "\n",
       "         V8        V9       V10   ...         V20       V21       V22  \\\n",
       "0  1.224267 -0.036384  0.050075   ...    0.301116  0.240538  0.707201   \n",
       "1  0.438009 -0.487785 -0.816031   ...    0.816683  0.340005  0.171648   \n",
       "2  0.818499 -1.445239  0.202760   ...    0.866831  0.086957 -1.077871   \n",
       "3  0.418671  0.962524 -0.824186   ...    0.186004 -0.001488 -0.152296   \n",
       "4  0.414078 -0.757303 -0.289653   ...   -0.018858  0.198920  0.667377   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Amount  \n",
       "0 -0.251083 -0.450744  0.272565  0.567029  0.027397 -0.040843   82.24  \n",
       "1  0.960273  0.016460 -0.199284 -0.286972 -0.063034  0.074770  435.00  \n",
       "2  0.391329 -0.448916 -0.352105 -0.870777  0.077323 -0.479606  189.00  \n",
       "3  0.564498  0.738859 -0.708118  0.285887 -0.040291  0.018017  187.10  \n",
       "4 -0.051745  0.418866 -0.283271 -0.305879  0.312144  0.162622    2.18  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop('Time', 1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142403, 29)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean()) / (X_train.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroid = X_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.983843702344881e-14"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid.sum() #should be 0 or small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid.shape # should be (29,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is an outlier detection algorithm, some good values of $r$ to try are multiples of $\\sigma$, the standard deviation of the data points from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_distances = np.linalg.norm(X_train, axis=1) # since centroid.sum() was so small, I'm going to round to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142403,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_distances.shape # should be (142403,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma = train_distances.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_grid = np.arange(2, 6.1, 0.1) * sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load validation data\n",
    "X_val = pd.read_csv('X_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 30)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape #should be (56961, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop 'Time' and mean normalize\n",
    "X_val = X_val.drop('Time', 1)\n",
    "X_val = (X_val - X_val.mean()) / (X_val.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 29)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape # should be (56961, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_distances = np.linalg.norm(X_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_distances.shape # should be (56961,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = r_grid[0] #testing for for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12344,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_distances[val_distances >= r].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val = pd.read_csv('y_val.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape #should be (56961, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = np.zeros_like(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted[np.where(val_distances >= r)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12344"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.sum() #should be 12344"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use the ```roc_auc_score()``` function from scikit learn to calculate the area under the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86995898773496894"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = roc_auc_score(y_val, y_predicted)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.869959</td>\n",
       "      <td>5.162541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.878511</td>\n",
       "      <td>5.420668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.889149</td>\n",
       "      <td>5.678795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.899265</td>\n",
       "      <td>5.936922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.906535</td>\n",
       "      <td>6.195049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.914665</td>\n",
       "      <td>6.453176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.917795</td>\n",
       "      <td>6.711303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.919534</td>\n",
       "      <td>6.969430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.922986</td>\n",
       "      <td>7.227557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.923201</td>\n",
       "      <td>7.485684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.920601</td>\n",
       "      <td>7.743811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.912114</td>\n",
       "      <td>8.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.905774</td>\n",
       "      <td>8.260066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.902072</td>\n",
       "      <td>8.518193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.903111</td>\n",
       "      <td>8.776320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.901644</td>\n",
       "      <td>9.034447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.900071</td>\n",
       "      <td>9.292574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.898198</td>\n",
       "      <td>9.550701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.896255</td>\n",
       "      <td>9.808828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.886782</td>\n",
       "      <td>10.066955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.884856</td>\n",
       "      <td>10.325082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.864959</td>\n",
       "      <td>10.583209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.860394</td>\n",
       "      <td>10.841336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.853234</td>\n",
       "      <td>11.099463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.853807</td>\n",
       "      <td>11.357590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.849030</td>\n",
       "      <td>11.615717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.844281</td>\n",
       "      <td>11.873844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.829327</td>\n",
       "      <td>12.131971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.819466</td>\n",
       "      <td>12.390098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.814673</td>\n",
       "      <td>12.648225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.812386</td>\n",
       "      <td>12.906352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.810126</td>\n",
       "      <td>13.164479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.807892</td>\n",
       "      <td>13.422606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.805675</td>\n",
       "      <td>13.680734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.800882</td>\n",
       "      <td>13.938861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.801075</td>\n",
       "      <td>14.196988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.788514</td>\n",
       "      <td>14.455115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.775961</td>\n",
       "      <td>14.713242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.771097</td>\n",
       "      <td>14.971369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.766163</td>\n",
       "      <td>15.229496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.756143</td>\n",
       "      <td>15.487623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUC          r\n",
       "0   0.869959   5.162541\n",
       "1   0.878511   5.420668\n",
       "2   0.889149   5.678795\n",
       "3   0.899265   5.936922\n",
       "4   0.906535   6.195049\n",
       "5   0.914665   6.453176\n",
       "6   0.917795   6.711303\n",
       "7   0.919534   6.969430\n",
       "8   0.922986   7.227557\n",
       "9   0.923201   7.485684\n",
       "10  0.920601   7.743811\n",
       "11  0.912114   8.001938\n",
       "12  0.905774   8.260066\n",
       "13  0.902072   8.518193\n",
       "14  0.903111   8.776320\n",
       "15  0.901644   9.034447\n",
       "16  0.900071   9.292574\n",
       "17  0.898198   9.550701\n",
       "18  0.896255   9.808828\n",
       "19  0.886782  10.066955\n",
       "20  0.884856  10.325082\n",
       "21  0.864959  10.583209\n",
       "22  0.860394  10.841336\n",
       "23  0.853234  11.099463\n",
       "24  0.853807  11.357590\n",
       "25  0.849030  11.615717\n",
       "26  0.844281  11.873844\n",
       "27  0.829327  12.131971\n",
       "28  0.819466  12.390098\n",
       "29  0.814673  12.648225\n",
       "30  0.812386  12.906352\n",
       "31  0.810126  13.164479\n",
       "32  0.807892  13.422606\n",
       "33  0.805675  13.680734\n",
       "34  0.800882  13.938861\n",
       "35  0.801075  14.196988\n",
       "36  0.788514  14.455115\n",
       "37  0.775961  14.713242\n",
       "38  0.771097  14.971369\n",
       "39  0.766163  15.229496\n",
       "40  0.756143  15.487623"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = pd.DataFrame({'r': [], 'AUC': []})\n",
    "\n",
    "for r in r_grid:\n",
    "    row = {}\n",
    "    row['r'] = r\n",
    "    \n",
    "    y_predicted = np.zeros_like(y_val)\n",
    "    y_predicted[np.where(val_distances >= r)] = 1\n",
    "    row['AUC'] = roc_auc_score(y_val, y_predicted)\n",
    "    \n",
    "    auc = auc.append(row, ignore_index=True)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AUC    0.923201\n",
       "r      7.485684\n",
       "Name: 9, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.loc[auc['AUC'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92% just using Euclidean distance? Not bad! This algorithm is often improved by using a kernel, so I will also try that. The radial basis function kernel often does a good job:\n",
    "$$ K(\\mathbf{x}, \\mathbf{x}') = exp(-\\gamma||\\mathbf{x} - \\mathbf{x}'||^2) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1/n_features is a standard value for gamma, so I will try that first just for vizualization\n",
    "gamma = 1 / X_train.shape[1]\n",
    "train_dist_rbf = - gamma * train_distances.copy() ** 2\n",
    "val_dist_rbf = - gamma * val_distances.copy() ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_rbf = train_dist_rbf.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_grid = np.arange(2, 6.1, 0.1) * sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gamma_grid = np.arange(-20, 20) * 0.01 + gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc_rbf = pd.DataFrame({'gamma': [], 'r': [], 'AUC': []})\n",
    "\n",
    "for gamma in gamma_grid:\n",
    "    val_dist_rbf = - gamma * val_distances.copy() ** 2\n",
    "    train_dist_rbf = - gamma * train_distances.copy() ** 2\n",
    "    sigma_rbf = train_dist_rbf.std()\n",
    "    r_grid = np.arange(2, 6.1, 0.1) * sigma\n",
    "    \n",
    "    row = {}\n",
    "    row['gamma'] = gamma\n",
    "    \n",
    "    for r in r_grid:\n",
    "        row['r'] = r\n",
    "        \n",
    "        y_predicted = np.zeros_like(y_val)\n",
    "        y_predicted[np.where(val_dist_rbf >= r)] = 1\n",
    "        row['AUC'] = roc_auc_score(y_val, y_predicted)\n",
    "        auc_rbf = auc_rbf.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1640.000000\n",
       "mean        0.634919\n",
       "std         0.172547\n",
       "min         0.500000\n",
       "25%         0.500000\n",
       "50%         0.500000\n",
       "75%         0.829318\n",
       "max         0.924449\n",
       "Name: AUC, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_rbf['AUC'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a 0.1% improvement. In that case, stick with simplicity. Now, let's see how it performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.485684374791159"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = auc.loc[auc['AUC'].idxmax()].r\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load test data\n",
    "X_test = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 30)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape #should be (56961, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X_test.drop('Time', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 29)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = (X_test - X_test.mean()) / (X_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_distances = np.linalg.norm(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_distances.shape # should be (56961,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('y_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape #should be (56961, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted = np.zeros_like(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted[np.where(test_distances >= r)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90858154318377993"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_final = roc_auc_score(y_test, y_predicted)\n",
    "auc_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this model also generalizes well, which is encouraging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the Model\n",
    "The second task is updating the model as new data comes in. I will use the finite sliding training window for my algorithm based on the equations from Kloft and Laskov. For making updates, I will use the average-out method for choosing which points to remove. This removes the centroid and recalculates it as:\n",
    "$$ \\mathbf{c}' = \\mathbf{c} + \\frac {1} {n} (\\mathbf{x} - \\mathbf{c}) $$\n",
    "where $\\mathbf{c}$ is the old centroid vector, $\\mathbf{c}'$ is the new centroid vector, $\\mathbf{x}$ is the new data vector, and $n$ is the number of data vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make the loops easier, I will make the original centroid vector into a vector of zeros\n",
    "centroid[:] = 0\n",
    "centroid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid.shape #should be (29,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load update data\n",
    "X_update = pd.read_csv('X_update.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28482, 30)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_update.shape #should be (28482, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_update = X_update.drop('Time', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28482, 29)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_update.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_update = (X_update - X_update.mean()) / (X_update.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, see if majority of the points are predicted to be outliers\n",
    "y_predicted = np.zeros(X_update.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28482,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.shape #should be (28482,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_distances = np.linalg.norm(X_update - centroid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted[np.where(update_distances >= r)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049399620813145147"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_outliers = y_predicted.sum() / y_predicted.shape[0]\n",
    "frac_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if frac_outliers < 0.5: #it is in this example\n",
    "    n = X_train.shape[0]\n",
    "    \n",
    "    for row in X_update.iterrows():\n",
    "        centroid = centroid + (1 / n) * (row[1].values - centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010061674397263176"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid.sum() #should not be exactly zero anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Functions\n",
    "I'm assuming that only the needed features are input into the function. I am not assuming that the data is normalized. For now, I'm only making sure these functions work with DataFrames, since that is what I used to develop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r was a multiple of sigma\n",
    "multiplier = r / sigma\n",
    "multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_A_initialize(X_train):\n",
    "    '''\n",
    "    This function initializes the centroid anomaly detection algorithm. It makes sure that the initial data is mean\n",
    "    normalized, which makes calculating the centroid trivial (it is zeros). It calculates the distance each data point\n",
    "    is from the centroid and uses the standard devation of the distances to calculate r, the threshold distance for\n",
    "    classifying points as outliers or inliers.\n",
    "    \n",
    "    Inputs:\n",
    "        X_train: a DataFrame of features. All features will be used in the algorithm.\n",
    "        \n",
    "    Outputs:\n",
    "        centroid: the centroid of the training data, an array of zeros\n",
    "        r: the threshold distance from the centroid\n",
    "        n: the number of training datapoints\n",
    "    '''\n",
    "    #imports\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    #mean normalize the input\n",
    "    X_train = (X_train - X_train.mean()) / (X_train.std())\n",
    "\n",
    "    # the centroid should be zero, so I'm hardcoding that to avoid rounding errors\n",
    "    centroid = np.zeros(X_train.shape[1])\n",
    "    \n",
    "    # calculate r from data\n",
    "    train_distances = np.linalg.norm(X_train, axis=1) #centroid is zero, so distance is just the norm\n",
    "    multiplier = 2.9 #determined through validation\n",
    "    sigma = train_distances.std() #the standard deviation of the distances\n",
    "    r = multiplier * sigma #the distance threshold for outliers\n",
    "    \n",
    "    n = X_train.shape[0]\n",
    "    \n",
    "    return centroid, r, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_A_update(X_update, centroid, r, n):\n",
    "    '''\n",
    "    This function updates the centroid model based on new data in X_update. First, it predicts which data points are\n",
    "    outliers. It does this by calculating the distance of the points from the centroid. If the distance is greater than\n",
    "    or equal to the threshold, r, then the point is an outlier. If a majority of the points are not outliers, the\n",
    "    centroid gets updated.\n",
    "    \n",
    "    Inputs:\n",
    "        X_update: a DataFrame of features. All features will be used in the algorithm.\n",
    "        \n",
    "    Outputs:\n",
    "        centroid: the centroid of the training data\n",
    "        r: the threshold distance from the centroid\n",
    "        n: the number of training datapoints\n",
    "        y_predicted: returns the predictions for the data point. 0=inlier, 1=outlier\n",
    "    '''\n",
    "    #imports\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    #make sure X_update is mean normalized\n",
    "    X_update = (X_update - X_update.mean()) / (X_update.std())\n",
    "\n",
    "    # first, see if majority of the points are predicted to be outliers\n",
    "    update_distances = np.linalg.norm(X_update - centroid, axis=1)\n",
    "    y_predicted = np.zeros(X_update.shape[0]) #start with zeros\n",
    "    y_predicted[np.where(update_distances >= r)] = 1 #change to 1's where >= r\n",
    "    frac_outliers = y_predicted.sum() / y_predicted.shape[0] #calculate fraction of outliers\n",
    "    print(frac_outliers)\n",
    "\n",
    "    if frac_outliers < 0.5: #if a majority of the points are not outliers\n",
    "        #update the model\n",
    "        for row in X_update.iterrows():\n",
    "            centroid = centroid + (1 / n) * (row[1].values - centroid)\n",
    "        print(\"centroid changed\")\n",
    "            \n",
    "    return centroid, r, n, y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load training data\n",
    "X_train = pd.read_csv('X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop('Time', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load update data\n",
    "X_update = pd.read_csv('X_update.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_update = X_update.drop('Time', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centroid, r, n = model_A_initialize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4856843747911572"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r # should be ~7.48568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142403"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n #should be 142403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0493996208131\n",
      "centroid changed\n"
     ]
    }
   ],
   "source": [
    "centroid, r, n, y_predicted = model_A_update(X_update, centroid, r, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010061674397263176"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid.sum() #should not be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4856843747911572"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r #should not have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142403"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n #should not have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1407.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
