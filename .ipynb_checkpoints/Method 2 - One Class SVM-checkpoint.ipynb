{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Class SVM\n",
    "A one class support vector machine (SVM) is an SVM modified to create a boundary around a single class and classify points beyond the boundary as outliers. The algorithm is based on Schölkopf B, Williamson RC, Smola AJ, Shawe-Taylor J, Platt JC. <a href=\"https://www.researchgate.net/publication/221619107_Support_Vector_Method_for_Novelty_Detection\">Support Vector Method for Novelty Detection</a>. Advances in Neural Information Processing Systems 12, [NIPS Conference, Denver, Colorado, USA, November 29 - December 4, 1999]. 1999. pp. 582–588.\n",
    "\n",
    "Essentially, a one class SVM algorithm treats the origin in feature space as the second class. It then maximizes the distance between the origin and the support vectors, with the decision hyperplane bisecting that distance. As with regular SVM, slack variables can be used to create a soft boundary.\n",
    "\n",
    "According to Microsoft Azure's <a href=\"https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-algorithm-cheat-sheet\">helpful cheatsheet</a>, one class SVM is good for data with > 100 features. While the dataset I'm using only has 30 features, UnifyID uses 100s of features in their implicit authentication algorithm. I thought it would be useful to practice this algorithm for the future.\n",
    "\n",
    "I will be using the scikit learn implementation.\n",
    "\n",
    "See ```Data Exploration and Setup.ipynb``` for more information on the data set used and how it was split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load training data\n",
    "X_train = pd.read_csv('X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142403, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #should be (142403, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I can't determine unique credit cards, I'm going to drop the 'Time' feature. I'm also going to mean normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop('Time', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142403, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean()) / (X_train.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing the model just on one parameter set first\n",
    "#linear worked for the centroid model, so might as well start there\n",
    "model_test = svm.OneClassSVM(nu=0.01, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto',\n",
       "      kernel='linear', max_iter=-1, nu=0.01, random_state=None,\n",
       "      shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load validation data\n",
    "X_val = pd.read_csv('X_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape #should be (56961, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop 'Time' and mean normalize\n",
    "X_val = X_val.drop('Time', 1)\n",
    "X_val = (X_val - X_val.mean()) / (X_val.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 29)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape # should be (56961, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = model_test.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val = pd.read_csv('y_val.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape #should be (56961, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the sklearn algorithm uses -1 for normal points, so I need to change 0s to 1s\n",
    "y_val[y_val==0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[0].unique() #check that there's only 1's and -1's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll use the ```roc_auc_score()``` function from scikit learn to calculate the area under the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72863286158293139"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = roc_auc_score(y_val, y_predict)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering this is likely not the optimal model for this dataset, this result isn't bad. Now to test out a few more hyperparameters. Unfortunately, ```GridSearchCV()``` with scikit learn requires y_true to have more that one class, so the grid search will have to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm going to try the radial basis function kernel and a linear kernel (no transformation)\n",
    "kernels = ['rbf', 'linear']\n",
    "nus = [0.1, 0.01, 0.001]\n",
    "gammas = [0.1, 0.01, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc = pd.DataFrame({'kernel': [], 'nu': [], 'gamma': [], 'AUC': []})\n",
    "row = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    row['kernel'] = kernel\n",
    "\n",
    "    for nu in nus:\n",
    "        row['nu'] = nu\n",
    "        \n",
    "        if kernel == 'rbf':\n",
    "            for gamma in gammas:\n",
    "                row['gamma'] = gamma\n",
    "\n",
    "                model = svm.OneClassSVM(nu=nu, kernel=kernel, gamma=gamma)\n",
    "                model.fit(X_train)\n",
    "                y_predict = model.predict(X_val)\n",
    "                row['AUC'] = roc_auc_score(y_val, y_predict)\n",
    "                auc = auc.append(row, ignore_index=True)\n",
    "        else:\n",
    "            row['gamma'] = 'NA'\n",
    "            \n",
    "            model = svm.OneClassSVM(nu=nu, kernel=kernel)\n",
    "            model.fit(X_train)\n",
    "            y_predict = model.predict(X_val)\n",
    "            row['AUC'] = roc_auc_score(y_val, y_predict)\n",
    "            auc = auc.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>nu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085154</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088529</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088741</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083976</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.098986</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.178050</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.083994</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.167384</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.400959</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.808935</td>\n",
       "      <td>NA</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.728633</td>\n",
       "      <td>NA</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.644496</td>\n",
       "      <td>NA</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AUC  gamma  kernel     nu\n",
       "0   0.085154    0.1     rbf  0.100\n",
       "1   0.088529   0.01     rbf  0.100\n",
       "2   0.088741  0.001     rbf  0.100\n",
       "3   0.083976    0.1     rbf  0.010\n",
       "4   0.098986   0.01     rbf  0.010\n",
       "5   0.178050  0.001     rbf  0.010\n",
       "6   0.083994    0.1     rbf  0.001\n",
       "7   0.167384   0.01     rbf  0.001\n",
       "8   0.400959  0.001     rbf  0.001\n",
       "9   0.808935     NA  linear  0.100\n",
       "10  0.728633     NA  linear  0.010\n",
       "11  0.644496     NA  linear  0.001"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training took a while, so writing this to csv for later\n",
    "auc.to_csv('svm_grid_search.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the choice of parameters is linear kernel with nu=0.1. The AUC is still a bit low, but that is to be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final = svm.OneClassSVM(nu=0.1, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto',\n",
       "      kernel='linear', max_iter=-1, nu=0.1, random_state=None,\n",
       "      shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load test data\n",
    "X_test = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 30)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape #should be (56961, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.drop('Time', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 29)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = (X_test - X_test.mean()) / (X_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict = model_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('y_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56961, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape #should be (56961, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80465502188694538"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, y_predict)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, the model generalizes well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the Model\n",
    "Since the hyperplane is calculated using only the support vectors, all of the initial non vector points can be discarded. For updates, the previous support vectors plus the new data will be input back into ```OneClassSVM()```. $\\nu$ will be set to n_support_vectors / (n_support_vectors + n_new_data). Because $\\nu$ puts a lower bound on the fraction of support vectors, this means the algorithm will use at least n_support_vectors as the new support vectors. To avoid the possibility of an infitiely growing number of support vectors, n_support_vectors can stay constant at the number of support vectors from the initial training\n",
    "\n",
    "This is an idea and algorithm I developed based on my knowledge of SVMs. To my knowledge, this update algorithm has not been published by anyone else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "support_vectors = model_final.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14762, 29)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_vectors.shape # should have 29 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_support_vectors = support_vectors.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load update data\n",
    "X_update = pd.read_csv('X_update.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28482, 30)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_update.shape #should be (28482, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_update = X_update.drop('Time', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28482, 29)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_update.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_update = (X_update - X_update.mean()) / (X_update.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#see how many are outliers\n",
    "y_predict = model_final.predict(X_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31110877045151325"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneClassSVM() outputs 1 for outliers and -1 for normal\n",
    "y_predict[y_predict==-1] = 0\n",
    "frac_outliers = y_predict.sum() / y_predict.shape[0]\n",
    "frac_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if frac_outliers < 0.5:\n",
    "    n_new_data = X_update.shape[0]\n",
    "    \n",
    "    #combine the support vectors and the new data points\n",
    "    X_new = np.vstack((support_vectors, X_update.values))\n",
    "    \n",
    "    #recalculate nu\n",
    "    nu = n_support_vectors / (n_support_vectors + n_new_data)\n",
    "    \n",
    "    #fit the new data\n",
    "    model_update = svm.OneClassSVM(nu=nu, kernel='linear')\n",
    "    model_update.fit(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43244, 29)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape #should be (43244, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14989, 29)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_update.support_vectors_.shape #should be ~14762"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Functions\n",
    "I'm assuming that only the needed features are input into the function. I am not assuming that the data is normalized. For now, I'm only making sure these functions work with DataFrames, since that is what I used to develop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_B_initialize(X_train):\n",
    "    \"\"\"\n",
    "    This algorithm implements the inital training for the OneClassSVM() algorithm from scikit learn. Hyperparameters\n",
    "    were optimized previously to nu = 0.1 and kernel = 'linear'.\n",
    "    \n",
    "    Inputs:\n",
    "        X_train: A DataFrame of features. All features are input into the model.\n",
    "        \n",
    "    Output:\n",
    "        model: The OneClassSVM() model object with stored fit results.\n",
    "        n_support_vectors: The number of suport vectors used by the algorithm.\n",
    "    \"\"\"\n",
    "    #imports\n",
    "    import pandas as pd\n",
    "    from sklearn import svm\n",
    "    \n",
    "    #make sure X_train is mean normalized\n",
    "    X_train = (X_train - X_train.mean()) / (X_train.std())\n",
    "\n",
    "    # create model\n",
    "    model = svm.OneClassSVM(nu=0.1, kernel='linear') #hyperparameters found through validation\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(X_train)\n",
    "    \n",
    "    #extract the number of support vectors\n",
    "    support_vectors = model.support_vectors_\n",
    "    n_support_vectors = support_vectors.shape[0]\n",
    "\n",
    "    return model, n_support_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_B_update(X_update, model, n_support_vectors):\n",
    "    \"\"\"\n",
    "    This function updates the OneClassSVM() algorithm with new data. It uses the support vectors from the previous\n",
    "    model and the new data to train a new model. This data set is much smaller than the original, so training is \n",
    "    faster. nu is also set to be n_support_vectors / (n_support_vectors + n_new_data) so that the number of support\n",
    "    vectors stays roughly constant. n_support_vectors is held constant across updates, but the support vectors are\n",
    "    updated every time.\n",
    "    \n",
    "    Inputs:\n",
    "        X_update: a DataFrame of features. All features will be used in the algorithm.\n",
    "        model: The OneClassSVN() model object from the previous training. The model must include fit results.\n",
    "        n_support_vectors: The number of support vectors generated in the initial training\n",
    "        \n",
    "    Outputs:\n",
    "        model_update: The updated OneClassSVM() model object with stored fit results.\n",
    "        y_predict: The predictions for each data point. 0=normal, 1=outlier.\n",
    "    \"\"\"\n",
    "    #imports\n",
    "    import pandas as pd\n",
    "    from sklearn import svm\n",
    "    \n",
    "    #extract the support vectors\n",
    "    support_vectors = model.support_vectors_\n",
    "\n",
    "    X_update = (X_update - X_update.mean()) / (X_update.std())\n",
    "\n",
    "    #see how many are outliers\n",
    "    y_predict = model.predict(X_update)\n",
    "\n",
    "    # OneClassSVM() outputs 1 for outliers and -1 for normal\n",
    "    y_predict[y_predict==-1] = 0\n",
    "    frac_outliers = y_predict.sum() / y_predict.shape[0]\n",
    "\n",
    "    if frac_outliers < 0.5:\n",
    "        n_new_data = X_update.shape[0]\n",
    "\n",
    "        #combine the support vectors and the new data points\n",
    "        X_new = np.vstack((support_vectors, X_update.values))\n",
    "\n",
    "        #recalculate nu\n",
    "        nu = n_support_vectors / (n_support_vectors + n_new_data)\n",
    "\n",
    "        #fit the new data\n",
    "        model_update = svm.OneClassSVM(nu=nu, kernel='linear')\n",
    "        model_update.fit(X_new)\n",
    "        \n",
    "    return model_update, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load training data\n",
    "X_train = pd.read_csv('X_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop('Time', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load update data\n",
    "X_update = pd.read_csv('X_update.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_update = X_update.drop('Time', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, n_support_vectors = model_B_initialize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14762, 29)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.support_vectors_.shape #should be (14762, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14762"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_support_vectors #should be 14762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_update, y_predict = model_B_update(X_update, model, n_support_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14989, 29)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_update.support_vectors_.shape #should be (14989, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8861.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
